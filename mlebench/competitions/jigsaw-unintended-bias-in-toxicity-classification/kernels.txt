thousandvoices/simple-lstm
bminixhofer/simple-lstm-pytorch-version
yuval6967/toxic-bert-plain-vanila
christofhenkel/how-to-preprocessing-for-glove-part2-usage
christofhenkel/how-to-preprocessing-for-glove-part1-eda
bminixhofer/speed-up-your-rnn-with-sequence-bucketing
abhishek/pytorch-bert-inference
kunwar31/simple-lstm-with-identity-parameters-fastai
christofhenkel/keras-baseline-lstm-attention-5-fold
nz0722/simple-eda-text-preprocessing-jigsaw
dborkan/benchmark-kernel
tanreinama/simple-lstm-using-identity-parameters-solution
adityaecdrid/public-version-text-cleaning-vocab-65
gpreda/jigsaw-fast-compact-solution
christofhenkel/bert-embeddings-lstm
artgor/cnn-in-keras-on-folds
nholloway/the-effect-of-word-embeddings-on-bias
ekhtiar/unintended-eda-with-tutorial-notes
taindow/simple-cudnngru-python-keras
timon88/bert-lstm-simple-blender-0-93844-lb
gpreda/jigsaw-eda
christofhenkel/loading-bert-using-pytorch-with-tokenizer-apex
taindow/bert-a-fine-tuning-example
cristinasierra/pretext-lstm-tuning-v3
sakami/pytorch-base-model
artgor/toxicity-eda-logreg-and-nn-interpretation
chechir/bert-lstm-rank-blender
gazu468/all-about-bert-you-need-to-know
tarunpaparaju/jigsaw-competition-eda-and-modeling
adityaecdrid/regex-primer-annoying-artgor-xd
abhishek/convert-lines-faster-for-bert
iezepov/wombat-inference-kernel
chriscc/jigsaw-starter-blend
abhigupta4981/pytorch-train-with-callbacks
sakami/single-lstm-3rd-place
christofhenkel/temporal-cnn
fulrose/kakr-4th-seminar-feature-engineering
coolcoder22/colab-to-fine-tune-bert
kabure/simple-eda-hard-views-w-easy-code
httpwwwfszyc/bert-keras-with-warmup-and-excluding-wd-parameters
yuval6967/toxic-train-bert-base-pytorch
yasufuminakama/jigsaw4-luke-base-starter-train
kyakovlev/preprocessing-bert-public
nz0722/reasoning-some-text-clean-not-work
abdalrahmanshahrour/toxic-text-classification
haqishen/jigsaw-predict
christofhenkel/ulmfit-fast-ai-starter
artgor/comparing-architectures-and-embeddings
tanreinama/pretext-lstm-tuning-v3-with-ensemble-tune
kenkrige/bert-inference-for-upload
